{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee54e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import geopandas as gdp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "from scipy import sparse\n",
    "from scipy.linalg import solve\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "from laos_gggi.shapefiles_data_loader import load_shapefile\n",
    "from laos_gggi.GPCC_data_loader import download_gpcc_data\n",
    "from laos_gggi.emdat_processing import process_emdat\n",
    "from laos_gggi.const_vars import COUNTRIES_ISO, ISO_DICTIONARY\n",
    "\n",
    "from libpysal.weights import Queen, KNN, fuzzy_contiguity, w_union, W\n",
    "from esda.moran import Moran\n",
    "import networkx as nx\n",
    "import warnings\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59821527",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1841245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_df = download_gpcc_data(repair_ISO_codes=True)\n",
    "world = load_shapefile('world', repair_ISO_codes=True)\n",
    "laos = load_shapefile('laos')\n",
    "data = process_emdat()\n",
    "\n",
    "df_prob = data[\"df_prob_filtered_adjusted\"].drop(['Region', \"Subregion\"], axis=1)\n",
    "df_inten = data[\"df_inten_filtered_adjusted\"].drop(['Region'], axis=1)\n",
    "\n",
    "df_prob = (df_prob.reset_index()\n",
    "     .assign(**{'Start_Year': lambda x: pd.to_datetime(x['Start_Year'], format='%Y')})\n",
    "     .set_index(['ISO', 'Start_Year']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfa55ae",
   "metadata": {},
   "source": [
    "## Reconsile EMDAT and shapefile ISO codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec923171",
   "metadata": {},
   "outputs": [],
   "source": [
    "world.set_index('ISO_A3', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc160588",
   "metadata": {},
   "outputs": [],
   "source": [
    "emdat_iso = df_prob.index.get_level_values(0).unique()\n",
    "world_iso = world.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes in EMDAT but not in world\n",
    "# These are all historical:\n",
    "\", \".join(list(set(emdat_iso) - set(world_iso)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327b4c90",
   "metadata": {},
   "source": [
    "From ChatGPT -- Check\n",
    "\n",
    "- ANT - Netherlands Antilles (dissolved in 2010)\n",
    "- YUG - Yugoslavia (dissolved in the early 1990s)\n",
    "- DFR - German Democratic Republic (East Germany, merged with West Germany in 1990)\n",
    "- CSK - Czechoslovakia (split into Czech Republic and Slovakia in 1993)\n",
    "- DDR - German Democratic Republic (East Germany, same as DFR)\n",
    "- SPI - Spain\n",
    "- YMD - Yemen Democratic Republic (South Yemen, unified with North Yemen in 1990)\n",
    "- TWN - Taiwan (Republic of China)\n",
    "- SCG - Serbia and Montenegro (dissolved in 2006)\n",
    "- MTQ - Martinique\n",
    "- SUN - Soviet Union (dissolved in 1991)\n",
    "- GUF - French Guiana\n",
    "- REU - Réunion\n",
    "- TKL - Tokelau\n",
    "- YMN - Yemen (Republic of Yemen)\n",
    "- AZO - Azores (part of Portugal)\n",
    "- GLP - Guadeloupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes in shapefile but not in EMDAT\n",
    "\", \".join(list(set(world_iso) - set(emdat_iso)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec7bec",
   "metadata": {},
   "source": [
    "From ChatGPT -- Check\n",
    "\n",
    "- PCN - Pitcairn Islands\n",
    "- NFK - Norfolk Island\n",
    "- HMD - Heard Island and McDonald Islands\n",
    "- ATF - French Southern and Antarctic Lands\n",
    "- GGY - Guernsey\n",
    "- AND - Andorra\n",
    "- BHR - Bahrain\n",
    "- VAT - Vatican City (Holy See)\n",
    "- SPM - Saint Pierre and Miquelon\n",
    "- FRO - Faroe Islands\n",
    "- NRU - Nauru\n",
    "- GRL - Greenland\n",
    "- IOT - British Indian Ocean Territory\n",
    "- JEY - Jersey\n",
    "- FLK - Falkland Islands\n",
    "- UNK - United Nations (used for various purposes)\n",
    "- MCO - Monaco\n",
    "- LIE - Liechtenstein\n",
    "- SGP - Singapore\n",
    "- CUW - Curaçao\n",
    "- SMR - San Marino\n",
    "- GNQ - Equatorial Guinea\n",
    "- ABW - Aruba\n",
    "- GIB - Gibraltar\n",
    "- SGS - South Georgia and the South Sandwich Islands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96939fec",
   "metadata": {},
   "source": [
    "## Drop codes not in both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c702e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_codes = set(world_iso).intersection(set(emdat_iso))\n",
    "df_prob = df_prob.loc[lambda x: x.index.get_level_values(0).isin(common_codes)].copy()\n",
    "df_inten = df_inten.loc[lambda x: x.index.get_level_values(0).isin(common_codes)].copy()\n",
    "world = world.loc[world.index.isin(common_codes)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a012fa1",
   "metadata": {},
   "source": [
    "## Get unique iso codes and years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd692cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_idx, codes = pd.factorize(df_prob.index.get_level_values(0), sort=True)\n",
    "year_idx, years = pd.factorize(df_prob.index.get_level_values(1), sort=True)\n",
    "disasters = df_prob.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc9ff55",
   "metadata": {},
   "source": [
    "# Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(14, 6), dpi=144)\n",
    "for axis, disaster in zip_longest(fig.axes, disasters):    \n",
    "    if disaster is None:\n",
    "        axis.set_visible(False)\n",
    "        continue\n",
    "        \n",
    "    disaster_2000s = df_prob.loc['2000':, [disaster]].groupby(level=0).sum()\n",
    "    disaster_2000s = (disaster_2000s - disaster_2000s.mean()) / disaster_2000s.std()\n",
    "    pd.merge(world, disaster_2000s, left_index=True, right_index=True).plot(disaster, ax=axis, cmap='YlGn', edgecolor='k', lw=0.25)\n",
    "    axis.set_title(disaster)\n",
    "    axis.axis('off')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943acb84",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4bde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings(action='ignore'):\n",
    "    # Make graph of bordering countires\n",
    "    w1 = fuzzy_contiguity(world)\n",
    "    \n",
    "    # Robustness of statistics to choice of k?\n",
    "    w2 = KNN.from_dataframe(world, k=2)    \n",
    "    w = w_union(w1, w2)\n",
    "    keys = sorted(list(w.neighbors.keys()))\n",
    "    \n",
    "    G = w.to_networkx().to_undirected()\n",
    "    \n",
    "    # Discard all but the main connected component (largest connected subgraph)\n",
    "    G = nx.subgraph(G, list(nx.connected_components(G))[0])\n",
    "    \n",
    "    # Make a dataset of only the regions in the resulting graph\n",
    "    connected_world = world.iloc[list(G.nodes)].copy()\n",
    "    idx_to_name = dict(enumerate(keys))\n",
    "    \n",
    "    # Change node names from numbers to ISO codes and do a sanity check\n",
    "    G = nx.relabel_nodes(G, idx_to_name)\n",
    "    assert list(G['USA'].keys()) == ['CAN', 'MEX']\n",
    "    \n",
    "    \n",
    "    # Compute the weight matrix resulting from the graph and do a sanity check\n",
    "    w = W.from_networkx(G)\n",
    "    w.remap_ids(list(G.nodes))\n",
    "    assert w.neighbors['USA'] == ['CAN', 'MEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f217e-c712-4c81-ad6e-dc60000f8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the adjacency matrix\n",
    "A = nx.adjacency_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf46a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute node positions for network graph (spring layout)\n",
    "pos = nx.drawing.nx_pydot.graphviz_layout(G, 'neato')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e1d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(14, 9), dpi=144)\n",
    "\n",
    "for axis, disaster in zip_longest(fig.axes, df_prob):\n",
    "    if disaster is None:\n",
    "        axis.set_visible(False)\n",
    "        continue\n",
    "    \n",
    "    merged_df = connected_world.join(df_prob.unstack(1).fillna(0)[disaster]) \n",
    "    \n",
    "    node_data = merged_df.loc[:, years[-25:]].sum(axis=1)\n",
    "    node_data = (node_data - node_data.mean()) / node_data.std()\n",
    "    node_dict = node_data.to_dict()\n",
    "    vmin, vmax = node_data.quantile([0.05, 0.95])\n",
    "    \n",
    "    nx.draw_networkx_nodes(G, pos, node_size=25, node_color=[node_dict.get(n) for n in G.nodes],\n",
    "                           ax=axis,\n",
    "                           vmin=vmin, vmax=vmax)\n",
    "    nx.draw_networkx_edges(G, pos, ax=axis)\n",
    "    axis.set_title(disaster)\n",
    "    axis.axis('off')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d89b3a",
   "metadata": {},
   "source": [
    "# Spatial Autocorrelation (Moran's I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc0f20",
   "metadata": {},
   "source": [
    "### Sum since 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2edd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stars(p):\n",
    "    if p < 0.01:\n",
    "        return '***'\n",
    "    if p < 0.05:\n",
    "        return '**'\n",
    "    if p < 0.1: \n",
    "        return '*'\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcff4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"Disaster\":<22}{\"Moran I\":>15}{\"P-value\":>15}')\n",
    "print('-'*60)\n",
    "for disaster in disasters:\n",
    "    merged_df = connected_world.join(df_prob.unstack(1).fillna(0)[disaster])\n",
    "    node_data = merged_df.loc[:, years[-25:]].sum(axis=1)\n",
    "    node_data = (node_data - node_data.mean()) / node_data.std()\n",
    "    mi = Moran(node_data, w)\n",
    "    print(f'{disaster:<20} {mi.I:>15.3f}{get_stars(mi.p_norm)}{mi.p_norm:>15.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c4484e",
   "metadata": {},
   "source": [
    "### Year-by-year, full sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d3e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.DataFrame(np.nan, columns=df_prob.columns, index=years)\n",
    "for disaster in disasters:\n",
    "    merged_df = connected_world.join(df_prob.unstack(1).fillna(0)[disaster])\n",
    "    for year in years:\n",
    "        with warnings.catch_warnings(action='ignore'):\n",
    "            mi = Moran(merged_df[year], w)\n",
    "            corr_df.loc[year, disaster] = mi.I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(14, 6), dpi=144, sharex=True)\n",
    "for axis, disaster in zip_longest(fig.axes, disasters):\n",
    "    if disaster is None:\n",
    "        axis.set_visible(False)\n",
    "        continue\n",
    "    corr_df[disaster].plot(ax=axis)\n",
    "    axis.set_title(disaster)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdb3b59",
   "metadata": {},
   "source": [
    "## Rolling 10-year average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c74f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.DataFrame(np.nan, columns=df_prob.columns, index=years[10:])\n",
    "for disaster in disasters:\n",
    "    merged_df = (connected_world.join(df_prob.unstack(1).fillna(0)[disaster])\n",
    "                     .loc[:, years]\n",
    "                     .T)\n",
    "    for start, stop in zip(years[:-10], years[10:]):\n",
    "        with warnings.catch_warnings(action='ignore'):\n",
    "            mi = Moran(merged_df.loc[start:stop].mean(), w)\n",
    "            corr_df.loc[start, disaster] = mi.I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(14, 6), dpi=144)\n",
    "for axis, disaster in zip_longest(fig.axes, disasters):\n",
    "    if disaster is None:\n",
    "        axis.set_visible(False)\n",
    "        continue\n",
    "    corr_df[disaster].plot(ax=axis)\n",
    "    axis.set_title(disaster)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54337a39",
   "metadata": {},
   "source": [
    "# Variograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c7b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skgstat as skg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb26834",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = (world.geometry\n",
    "                 .to_crs('EPSG:3857')\n",
    "                 .centroid\n",
    "                 .apply(lambda x: pd.Series({'x':x.x, 'y':x.y}))\n",
    "                 .mul(1e-3)) # convert meters to km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af51b4f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(14, 8), dpi=144)\n",
    "for axis, disaster in zip_longest(fig.axes, disasters):\n",
    "    if disaster is None:\n",
    "        axis.set_visible(False)\n",
    "        continue\n",
    "    \n",
    "    merged_df = (world.join(df_prob.unstack(1).fillna(0)[disaster])\n",
    "                     .loc[:, years[-25:]]\n",
    "                     .sum(axis=1))\n",
    "    V = skg.Variogram(coordinates=centroids,\n",
    "                      values=merged_df,\n",
    "                      estimator='matheron',\n",
    "                      dist_func='euclidean',\n",
    "                      model='matern',\n",
    "                      n_lags=50,\n",
    "                      use_nugget=True)\n",
    "    hist_ax = axis.inset_axes(bounds=[0, 0.75, 1.0, 0.25])\n",
    "    V.plot(axes=[axis, hist_ax], show=False, grid=False)\n",
    "    ticks = [x for x in hist_ax.xaxis.get_majorticklocs()]\n",
    "    hist_ax.set_yticklabels([])\n",
    "    hist_ax.set_xticklabels([])\n",
    "    \n",
    "    axis.set(title=disaster, xlabel = 'Lag (km)')\n",
    "    axis.tick_params(axis='x', labelbottom=True)\n",
    "\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c40c1c-5577-4723-8b8e-909ead027292",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b93cc-3a58-4109-bb7b-a363c2f79ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the random seed for sampling\n",
    "RANDOM_SEED = 8926\n",
    "rng = np.random.default_rng(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d40fd-af8e-4fb4-9c8f-6c6cae394152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling factor function\n",
    "def scaling_factor_sp(A):\n",
    "    \"\"\"Compute the scaling factor from an adjacency matrix.\n",
    "    This function uses sparse matrix computations and is most\n",
    "    efficient on sparse adjacency matrices. Used in the BYM2 model.\n",
    "    The scaling factor is a measure of the variance in the number of\n",
    "    edges across nodes in a connected graph.\n",
    "    Only works for fully connected graphs. The argument for scaling\n",
    "    factors is developed by Andrea Riebler, Sigrunn H. Sørbye,\n",
    "    Daniel Simpson, Havard Rue in \"An intuitive Bayesian spatial\n",
    "    model for disease mapping that accounts for scaling\"\n",
    "    https://arxiv.org/abs/1601.01180\"\"\"\n",
    "\n",
    "    # Computes the precision matrix in sparse format\n",
    "    # from an adjacency matrix.\n",
    "\n",
    "    num_neighbors = A.sum(axis=1)\n",
    "    A = sparse.csc_matrix(A)\n",
    "    D = sparse.diags(num_neighbors, format=\"csc\")\n",
    "    Q = D - A\n",
    "\n",
    "    # add a small jitter along the diagonal\n",
    "\n",
    "    Q_perturbed = Q + sparse.diags(np.ones(Q.shape[0])) * max(Q.diagonal()) * np.sqrt(\n",
    "        np.finfo(np.float64).eps\n",
    "    )\n",
    "\n",
    "    # Compute a version of the pseudo-inverse\n",
    "\n",
    "    n = Q_perturbed.shape[0]\n",
    "    b = sparse.identity(n, format=\"csc\")\n",
    "    Sigma = spsolve(Q_perturbed, b)\n",
    "    A = np.ones(n)\n",
    "    W = Sigma @ A.T\n",
    "    Q_inv = Sigma - np.outer(W * solve(A @ W, np.ones(1)), W.T)\n",
    "\n",
    "    # Compute the geometric mean of the diagonal on a\n",
    "    # precision matrix.\n",
    "\n",
    "    return np.exp(np.sum(np.log(np.diag(Q_inv))) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cdaab8-4d33-4b5b-b06f-f7bf5fed6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the scaling factor\n",
    "scaling_factor = scaling_factor_sp(A)\n",
    "scaling_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3680a8c-b527-4a3a-b667-766d7f4069c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the shapes of coords and dara\n",
    "df_prob = df_prob.drop([\"ASM\", \"CYP\", \"EGY\", \"PLW\", \"PRI\", \"SXM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b5eb8e-52c5-4e1e-9a67-ac0dd2b42a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining coords\n",
    "iso_idx, iso = pd.factorize(df_prob.reset_index()['ISO'])\n",
    "coords = {\"iso\": iso}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e19b859-f488-4807-bc0c-eaf2a5e7e8ef",
   "metadata": {},
   "source": [
    "## Spatial only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea02d04-8cd8-4ff5-ab2d-e3898233de13",
   "metadata": {},
   "source": [
    "### Drought"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57fa0a8-7125-4da8-b725-dac8fd2a9d6e",
   "metadata": {},
   "source": [
    "First, we sum over time to work only with space dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bf32b2-846b-4511-8aed-f451616f7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_space_drought = df_prob.pivot_table(values= ['Drought'] , index = \"ISO\" , aggfunc= \"sum\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facd6c7c-c63b-44f4-ba36-475e665348d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(coords=coords) as BYM_model:\n",
    "    # intercept\n",
    "    beta0 = pm.Normal(\"beta0\", mu =0, sigma = 1)\n",
    "\n",
    "    # independent random effect\n",
    "    theta = pm.Normal(\"theta\", mu = 0, sigma = 1, dims=\"iso\")\n",
    "\n",
    "    # spatially structured random effect\n",
    "    phi = pm.ICAR(\"phi\", W= A.todense())\n",
    "\n",
    "    # joint variance of random effects\n",
    "    sigma = pm.HalfNormal(\"sigma\", 1)\n",
    "    \n",
    "    # the mixing rate is rho\n",
    "    rho = pm.Beta(\"rho\", 0.5, 0.5)\n",
    "\n",
    "    # the bym component - it mixes a spatial and a random effect\n",
    "    mixture = pt.sqrt(1 - rho) * theta + pt.sqrt(rho / scaling_factor) * phi\n",
    "\n",
    "    # exponential link function to ensure\n",
    "    # predictions are positive\n",
    "    mu = pt.exp(beta0 + sigma * mixture)\n",
    "\n",
    "    y_i = pm.Poisson(\"y_i\", mu, observed=df_prob_space_drought[\"Drought\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c97be1-b2e3-4623-a56b-46dab85fd946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Sampling the model\n",
    "with BYM_model:\n",
    "    idata = pm.sample(draws = 500,chains = 8,  nuts_sampler=\"nutpie\", random_seed=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b9f08-2661-4db2-b356-200754461b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, var_names=[\"beta0\", \"sigma\", \"rho\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f55c2-9c96-4331-a9ee-cd0648337562",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata, var_names=[\"beta0\", \"sigma\", \"rho\"])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d863a-7715-4cd4-a429-d776e7b997ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_pred = idata.posterior.phi.mean((\"chain\", \"draw\")).values\n",
    "beta0_pred = idata.posterior.beta0.mean((\"chain\", \"draw\")).values\n",
    "sigma_pred = idata.posterior.sigma.mean((\"chain\", \"draw\")).values\n",
    "y_predict = np.exp( beta0_pred + sigma_pred * (1 / scaling_factor) * phi_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29fc2e-7aed-4097-9bd0-18c121958886",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw_networkx(\n",
    "    G,\n",
    "    pos=pos,\n",
    "    node_color=y_predict,\n",
    "    cmap=\"plasma\",\n",
    "    vmax=30,\n",
    "    width=0.5,\n",
    "    alpha=0.6,\n",
    "    with_labels=False,\n",
    "    node_size=20 + 3 * y_predict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17effb5c-cce0-404f-8f31-57c7a5404f38",
   "metadata": {},
   "source": [
    "### Flood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74aed04-8297-490b-b54c-d35d5ae4e543",
   "metadata": {},
   "source": [
    "First, we sum over time to work only with space dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882f316-fd27-4360-80d8-2e5add45d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_space_flood = df_prob.pivot_table(values= ['Flood'] , index = \"ISO\" , aggfunc= \"sum\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6711f-ecb4-49bd-803b-9711f076367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(coords=coords) as BYM_model:\n",
    "    # intercept\n",
    "    beta0 = pm.Normal(\"beta0\", mu =0, sigma = 1)\n",
    "\n",
    "    # independent random effect\n",
    "    theta = pm.Normal(\"theta\", mu = 0, sigma = 1, dims=\"iso\")\n",
    "\n",
    "    # spatially structured random effect\n",
    "    phi = pm.ICAR(\"phi\", W= A.todense())\n",
    "\n",
    "    # joint variance of random effects\n",
    "    sigma = pm.HalfNormal(\"sigma\", 1)\n",
    "    \n",
    "    # the mixing rate is rho\n",
    "    rho = pm.Beta(\"rho\", 0.5, 0.5)\n",
    "\n",
    "    # the bym component - it mixes a spatial and a random effect\n",
    "    mixture = pt.sqrt(1 - rho) * theta + pt.sqrt(rho / scaling_factor) * phi\n",
    "\n",
    "    # exponential link function to ensure\n",
    "    # predictions are positive\n",
    "    mu = pt.exp(beta0 + sigma * mixture)\n",
    "\n",
    "    y_i = pm.Poisson(\"y_i\", mu, observed=df_prob_space_flood[\"Flood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79174e1-4d95-4b53-8b48-d5e662c1ebd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Sampling the model\n",
    "with BYM_model:\n",
    "    idata = pm.sample(draws = 500,chains = 8,  nuts_sampler=\"nutpie\", random_seed=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40776a06-9993-4800-8d9a-1b8558adb37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, var_names=[\"beta0\", \"sigma\", \"rho\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80922b49-c85f-48a3-b191-e7d5aaf524ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata, var_names=[\"beta0\", \"sigma\", \"rho\"])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a465f5c7-eef1-430a-bbac-f6fd3e09a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_pred = idata.posterior.phi.mean((\"chain\", \"draw\")).values\n",
    "beta0_pred = idata.posterior.beta0.mean((\"chain\", \"draw\")).values\n",
    "sigma_pred = idata.posterior.sigma.mean((\"chain\", \"draw\")).values\n",
    "y_predict = np.exp( beta0_pred + sigma_pred * (1 / scaling_factor) * phi_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb2511-d478-4dff-8834-c2263e222ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw_networkx(\n",
    "    G,\n",
    "    pos=pos,\n",
    "    node_color=y_predict,\n",
    "    cmap=\"plasma\",\n",
    "    vmax=30,\n",
    "    width=0.5,\n",
    "    alpha=0.6,\n",
    "    with_labels=False,\n",
    "    node_size=20 + 3 * y_predict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dff5f8-92a6-4ef2-8eec-9dd03f41f3f6",
   "metadata": {},
   "source": [
    "### Storm                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d55ef-8803-468f-9868-f3e5494b03ce",
   "metadata": {},
   "source": [
    "First, we sum over time to work only with space dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c09ba9-9d9c-4a5d-8cf4-ff0814094fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_space_storm = df_prob.pivot_table(values= ['Storm'] , index = \"ISO\" , aggfunc= \"sum\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c22a2b-2fea-4baa-aea4-1306b9a11b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(coords=coords) as BYM_model:\n",
    "    # intercept\n",
    "    beta0 = pm.Normal(\"beta0\", mu =0, sigma = 1)\n",
    "\n",
    "    # independent random effect\n",
    "    theta = pm.Normal(\"theta\", mu = 0, sigma = 1, dims=\"iso\")\n",
    "\n",
    "    # spatially structured random effect\n",
    "    phi = pm.ICAR(\"phi\", W= A.todense())\n",
    "\n",
    "    # joint variance of random effects\n",
    "    sigma = pm.HalfNormal(\"sigma\", 1)\n",
    "    \n",
    "    # the mixing rate is rho\n",
    "    rho = pm.Beta(\"rho\", 0.5, 0.5)\n",
    "\n",
    "    # the bym component - it mixes a spatial and a random effect\n",
    "    mixture = pt.sqrt(1 - rho) * theta + pt.sqrt(rho / scaling_factor) * phi\n",
    "\n",
    "    # exponential link function to ensure\n",
    "    # predictions are positive\n",
    "    mu = pt.exp(beta0 + sigma * mixture)\n",
    "\n",
    "    y_i = pm.Poisson(\"y_i\", mu, observed= df_prob_space_storm[\"Storm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510e86ec-8d75-47b1-ad89-25780dc89c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_space_storm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d5c2c2-e14f-4b28-9aa4-633cde2296dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Sampling the model\n",
    "with BYM_model:\n",
    "    idata = pm.sample(draws = 500,chains = 8,  nuts_sampler=\"nutpie\", random_seed=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9472496-0879-4473-9ac8-9e700ad3300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, var_names=[\"beta0\", \"sigma\", \"rho\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe9beb-fcb0-4dda-983e-95d5b3f8566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata, var_names=[\"beta0\", \"sigma\", \"rho\"])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5888a67-84aa-4bba-b4f1-1de41950d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_pred = idata.posterior.phi.mean((\"chain\", \"draw\")).values\n",
    "beta0_pred = idata.posterior.beta0.mean((\"chain\", \"draw\")).values\n",
    "sigma_pred = idata.posterior.sigma.mean((\"chain\", \"draw\")).values\n",
    "y_predict = np.exp( beta0_pred + sigma_pred * (1 / scaling_factor) * phi_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e32e6-b7a1-4a45-bdd0-f46b41eea3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw_networkx(\n",
    "    G,\n",
    "    pos=pos,\n",
    "    node_color=y_predict,\n",
    "    cmap=\"plasma\",\n",
    "    vmax=30,\n",
    "    width=0.5,\n",
    "    alpha=0.6,\n",
    "    with_labels=False,\n",
    "    node_size=20 + 3 * y_predict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62af2b7-fbf1-4e9d-a309-c1e2d0becbf8",
   "metadata": {},
   "source": [
    "## Second version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91bebe9-3a39-42d2-8550-907219892146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding region and subregion columns\n",
    "regions = (data[\"df_prob_filtered_adjusted\"].pivot_table(values= ['Drought'] , index = [\"ISO\", \"Region\", \"Subregion\"] , aggfunc= \"sum\" )\n",
    " .reset_index().set_index([\"ISO\"])\n",
    " .drop([\"Drought\"], axis = 1)\n",
    "    )\n",
    "\n",
    "df_prob_reg =  pd.merge(df_prob, regions, left_index=True, right_index=True, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae637f-92d2-4e20-87e6-6ec548f6b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining coords\n",
    "iso_idx, iso = pd.factorize(df_prob_reg.reset_index()['ISO'])\n",
    "region_idx, region = pd.factorize(df_prob_reg.reset_index()['Region'])\n",
    "subregion_idx, subregion = pd.factorize(df_prob_reg.reset_index()['Subregion'])\n",
    "\n",
    "coords = coords = {\"iso\": iso, \"region\": region, \"subregion\": subregion}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b461e68-312e-4869-a42f-fceacf6fe843",
   "metadata": {},
   "source": [
    "### Drought"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40def1d-f3ad-40b4-9e4d-ed408bc8a1d8",
   "metadata": {},
   "source": [
    "First, we sum over time to work only with space dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76383ea8-9028-4119-b281-a2053a7ce63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_space_drought_second = (df_prob_reg.\n",
    "                                pivot_table(values= ['Drought'] , index = [\"ISO\", \"Region\", \"Subregion\"] , aggfunc= \"sum\" )\n",
    "                                .reset_index().set_index([\"ISO\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe3d35-0d3f-425a-911d-d13669885c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(coords=coords) as BYM_modeldrought_second:\n",
    "    # intercept 1\n",
    "    beta0 = pm.Normal(\"beta0\", mu =0, sigma = 1)\n",
    "\n",
    "    # intercept 2\n",
    "    beta1 = pm.ZeroSumNormal(\"beta1\",  dims = \"region\" )\n",
    "\n",
    "    # intercept\n",
    "    beta2 = pm.ZeroSumNormal(\"beta2\",  dims = \"subregion\" )\n",
    "\n",
    "    # independent random effect\n",
    "    theta = pm.Normal(\"theta\", mu = 0, sigma = 1, dims=\"iso\")\n",
    "\n",
    "    # spatially structured random effect\n",
    "    phi = pm.ICAR(\"phi\", W= A.todense())\n",
    "\n",
    "    # joint variance of random effects\n",
    "    sigma = pm.HalfNormal(\"sigma\", 1)\n",
    "    \n",
    "    # the mixing rate is rho\n",
    "    rho = pm.Beta(\"rho\", 0.5, 0.5)\n",
    "\n",
    "    # the bym component - it mixes a spatial and a random effect\n",
    "    mixture = pt.sqrt(1 - rho) * theta + pt.sqrt(rho / scaling_factor) * phi\n",
    "\n",
    "    # exponential link function to ensure\n",
    "    # predictions are positive\n",
    "    mu = pt.exp(beta0 + beta1[region_idx] + beta2[subregion_idx] + sigma * mixture)\n",
    "\n",
    "    y_i = pm.Poisson(\"y_i\", mu, observed=df_prob_space_drought[\"Drought\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b3a219-acbc-43aa-a9a7-6b27190204c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_space_drought[\"Drought\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf4d659-2bcb-4f84-80ff-1c7b70c1e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling the model\n",
    "with BYM_modeldrought_second:\n",
    "    idata = pm.sample(draws = 500,chains = 8,  nuts_sampler=\"nutpie\", random_seed=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afce734-2d7f-4216-ae62-869f82199a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(idata, var_names=[\"beta0\", \"sigma\", \"rho\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8cb411-9f0c-4729-a22a-318430595bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata, var_names=[\"beta0\", \"sigma\", \"rho\"])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b473e2d-6cb3-4d0b-b93c-b86d03f32f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_pred = idata.posterior.phi.mean((\"chain\", \"draw\")).values\n",
    "beta0_pred = idata.posterior.beta0.mean((\"chain\", \"draw\")).values\n",
    "sigma_pred = idata.posterior.sigma.mean((\"chain\", \"draw\")).values\n",
    "y_predict = np.exp( beta0_pred + sigma_pred * (1 / scaling_factor) * phi_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea4530c-147a-4405-9328-96b7b05f9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw_networkx(\n",
    "    G,\n",
    "    pos=pos,\n",
    "    node_color=y_predict,\n",
    "    cmap=\"plasma\",\n",
    "    vmax=30,\n",
    "    width=0.5,\n",
    "    alpha=0.6,\n",
    "    with_labels=False,\n",
    "    node_size=20 + 3 * y_predict,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
